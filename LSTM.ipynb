{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJoSyjHR6EU1"
      },
      "source": [
        "# **Chatbot with RNN LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfMVPits6rJ_"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1YASvCMeQn"
      },
      "source": [
        "import nltk\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input,Embedding, LSTM, Dense, GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0brNQStF6vN3"
      },
      "source": [
        "Uploading File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yEkgpBZqNEAY",
        "outputId": "1afae429-0630-480e-b14e-6d2d0a49b623"
      },
      "source": [
        "import io\n",
        "import os\n",
        "from google.colab import files\n",
        "## Uploading the file\n",
        "file_upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ef8f4fc-b122-4ef1-82dc-5d22989c6e3f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ef8f4fc-b122-4ef1-82dc-5d22989c6e3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.json to data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_0EPsZe6zjq"
      },
      "source": [
        "Data Preprocessing\n",
        "* Appending data to lists (tags and inputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjkJsSyqMeQv"
      },
      "source": [
        "# Getting all data to list\n",
        "tags=[]\n",
        "inputs = [] # pattern\n",
        "responses={}\n",
        "documents = []\n",
        "#ignore_words = ['?', '!']\n",
        "data_file = open('/content/data.json').read()\n",
        "data1 = json.loads(data_file)\n",
        "\n",
        "for intent in data1['intents']:\n",
        "    responses[intent['tag']]= intent['responses']\n",
        "    for lines in intent['patterns']:\n",
        "        inputs.append(lines)\n",
        "        tags.append(intent['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cFOMT4MeQw"
      },
      "source": [
        "pickle.dump(inputs,open('texts.pkl','wb'))\n",
        "pickle.dump(tags,open('labels.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8t4U2P3MeQy"
      },
      "source": [
        "# Converting to Pandas Dataframe\n",
        "data=pd.DataFrame({\"inputs\":inputs,\n",
        "                    \"tags\":tags})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gegiq1b6MeQ0",
        "outputId": "aa795f72-cbac-4b39-9a32-76bf125a0314"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  inputs                    tags\n",
            "0                               Hi there                greeting\n",
            "1                            How are you                greeting\n",
            "2                       Is anyone there?                greeting\n",
            "3                                    Hey                greeting\n",
            "4                                   Hola                greeting\n",
            "5                                  Hello                greeting\n",
            "6                               Good day                greeting\n",
            "7                                    Bye                 goodbye\n",
            "8                          See you later                 goodbye\n",
            "9                                Goodbye                 goodbye\n",
            "10             Nice chatting to you, bye                 goodbye\n",
            "11                        Till next time                 goodbye\n",
            "12                                Thanks                  thanks\n",
            "13                             Thank you                  thanks\n",
            "14                        That's helpful                  thanks\n",
            "15                       Awesome, thanks                  thanks\n",
            "16                 Thanks for helping me                  thanks\n",
            "17  What are some symptoms of depression             deepression\n",
            "18                    What is depression             deepression\n",
            "19                        Not that great                 feeling\n",
            "20                         I am stressed                 feeling\n",
            "21                               I’m sad                 feeling\n",
            "22                I am feeling depressed                 feeling\n",
            "23             I think I am overthinking            overthinking\n",
            "24                           I Overthink            overthinking\n",
            "25             I’m very confused in life   overthinking-continue\n",
            "26                 Tell me more about it  overthinking-continue1\n",
            "27                       You are awesome  overthinking-continue2\n",
            "28                          I'm all ears  overthinking-continue3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO_Nj-X9MeQ2"
      },
      "source": [
        "data=data.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "8bk8HwoNMeQ3",
        "outputId": "d13de4b3-ab84-44ae-b0f5-e475169319c6"
      },
      "source": [
        "# Import preprocessing to remove the punctuations\n",
        "import string\n",
        "data['inputs']= data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "data['inputs']=data['inputs'].apply(lambda wrd:''.join(wrd))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi there</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how are you</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is anyone there</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hey</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hola</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hello</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>good day</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bye</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>see you later</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>goodbye</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>nice chatting to you bye</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>till next time</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>thanks</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>thank you</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>thats helpful</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>awesome thanks</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>thanks for helping me</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>what are some symptoms of depression</td>\n",
              "      <td>deepression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>what is depression</td>\n",
              "      <td>deepression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>not that great</td>\n",
              "      <td>feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>i am stressed</td>\n",
              "      <td>feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i’m sad</td>\n",
              "      <td>feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>i am feeling depressed</td>\n",
              "      <td>feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>i think i am overthinking</td>\n",
              "      <td>overthinking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>i overthink</td>\n",
              "      <td>overthinking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>i’m very confused in life</td>\n",
              "      <td>overthinking-continue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>tell me more about it</td>\n",
              "      <td>overthinking-continue1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>you are awesome</td>\n",
              "      <td>overthinking-continue2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>im all ears</td>\n",
              "      <td>overthinking-continue3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  inputs                    tags\n",
              "0                               hi there                greeting\n",
              "1                            how are you                greeting\n",
              "2                        is anyone there                greeting\n",
              "3                                    hey                greeting\n",
              "4                                   hola                greeting\n",
              "5                                  hello                greeting\n",
              "6                               good day                greeting\n",
              "7                                    bye                 goodbye\n",
              "8                          see you later                 goodbye\n",
              "9                                goodbye                 goodbye\n",
              "10              nice chatting to you bye                 goodbye\n",
              "11                        till next time                 goodbye\n",
              "12                                thanks                  thanks\n",
              "13                             thank you                  thanks\n",
              "14                         thats helpful                  thanks\n",
              "15                        awesome thanks                  thanks\n",
              "16                 thanks for helping me                  thanks\n",
              "17  what are some symptoms of depression             deepression\n",
              "18                    what is depression             deepression\n",
              "19                        not that great                 feeling\n",
              "20                         i am stressed                 feeling\n",
              "21                               i’m sad                 feeling\n",
              "22                i am feeling depressed                 feeling\n",
              "23             i think i am overthinking            overthinking\n",
              "24                           i overthink            overthinking\n",
              "25             i’m very confused in life   overthinking-continue\n",
              "26                 tell me more about it  overthinking-continue1\n",
              "27                       you are awesome  overthinking-continue2\n",
              "28                           im all ears  overthinking-continue3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxdrr2JTMeQ5"
      },
      "source": [
        "# Tokenize the data \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer=Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['inputs'])\n",
        "train=tokenizer.texts_to_sequences(data['inputs'])\n",
        "\n",
        "# Apply Padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train=pad_sequences(train)\n",
        "\n",
        "# Encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y_train=le.fit_transform(data['tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHL1PysuMeQ7",
        "outputId": "752c34e5-c564-4cd1-a1b2-fbc473e8b433"
      },
      "source": [
        "input_shape=x_train.shape[1]\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSCijFOoMeQ9",
        "outputId": "05371b5e-1877-410c-c0c0-851eae9ff124"
      },
      "source": [
        "# Define Vocabulary\n",
        "vocabulary=len(tokenizer.word_index)\n",
        "print(\"number of unique words:\",vocabulary)\n",
        "output_length=le.classes_.shape[0]\n",
        "print(\"outputlength:\",output_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique words: 59\n",
            "outputlength: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnEJtH7pMeQ-"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L_b7xK_MeRD",
        "outputId": "f368e078-0f15-42cc-e7e4-6f8f7c541f9e"
      },
      "source": [
        "i=Input(shape=(input_shape,))\n",
        "x=Embedding(vocabulary+1,10)(i)\n",
        "x=LSTM(10,return_sequences=True)(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(output_length,activation=\"softmax\")(x)\n",
        "model= Model(i,x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 6)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 6, 10)             600       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 6, 10)             840       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 60)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,050\n",
            "Trainable params: 2,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRQAEA_BMeRI"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WKC19noMeRJ",
        "outputId": "0e9ecb47-0f68-4f27-80d3-da9ce29ef794"
      },
      "source": [
        "# Training the model\n",
        "train=model.fit(x_train,y_train,epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3080 - accuracy: 0.0690\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3056 - accuracy: 0.0690\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3032 - accuracy: 0.0690\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3009 - accuracy: 0.0690\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.1034\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2964 - accuracy: 0.3793\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2942 - accuracy: 0.3793\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2920 - accuracy: 0.3448\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2898 - accuracy: 0.3448\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2875 - accuracy: 0.3448\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2853 - accuracy: 0.3448\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2829 - accuracy: 0.3793\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2806 - accuracy: 0.3793\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2782 - accuracy: 0.3793\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2757 - accuracy: 0.3793\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2731 - accuracy: 0.3793\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2704 - accuracy: 0.3793\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2677 - accuracy: 0.3793\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2648 - accuracy: 0.3793\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2619 - accuracy: 0.3793\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2588 - accuracy: 0.3793\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2556 - accuracy: 0.3793\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2523 - accuracy: 0.3793\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2488 - accuracy: 0.3448\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2452 - accuracy: 0.3448\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2415 - accuracy: 0.3448\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2375 - accuracy: 0.3448\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2335 - accuracy: 0.3448\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2292 - accuracy: 0.3448\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2248 - accuracy: 0.2759\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2201 - accuracy: 0.2759\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2153 - accuracy: 0.2759\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2102 - accuracy: 0.2759\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2050 - accuracy: 0.2759\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1995 - accuracy: 0.2759\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.2759\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1878 - accuracy: 0.2759\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1815 - accuracy: 0.2759\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1751 - accuracy: 0.2759\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1683 - accuracy: 0.2759\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1613 - accuracy: 0.2759\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1540 - accuracy: 0.2759\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1465 - accuracy: 0.2759\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1387 - accuracy: 0.2759\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1306 - accuracy: 0.2759\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1222 - accuracy: 0.2759\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1136 - accuracy: 0.2759\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1047 - accuracy: 0.2759\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0956 - accuracy: 0.2759\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0863 - accuracy: 0.2759\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0767 - accuracy: 0.2759\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0670 - accuracy: 0.2759\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0571 - accuracy: 0.2759\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0470 - accuracy: 0.2759\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0369 - accuracy: 0.2759\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0267 - accuracy: 0.2759\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0165 - accuracy: 0.2759\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0064 - accuracy: 0.2759\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9963 - accuracy: 0.2759\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9864 - accuracy: 0.2759\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9767 - accuracy: 0.2759\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9672 - accuracy: 0.2759\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9581 - accuracy: 0.2759\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9494 - accuracy: 0.2414\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9411 - accuracy: 0.2414\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9333 - accuracy: 0.2414\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9259 - accuracy: 0.2414\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9191 - accuracy: 0.2414\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9128 - accuracy: 0.2414\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9070 - accuracy: 0.2414\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9016 - accuracy: 0.2414\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8967 - accuracy: 0.2414\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8921 - accuracy: 0.2759\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8877 - accuracy: 0.2759\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8835 - accuracy: 0.2759\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8794 - accuracy: 0.2759\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8753 - accuracy: 0.2759\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8711 - accuracy: 0.2759\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8668 - accuracy: 0.2759\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8624 - accuracy: 0.2759\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8577 - accuracy: 0.2759\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8529 - accuracy: 0.2759\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8479 - accuracy: 0.2759\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8428 - accuracy: 0.2759\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8375 - accuracy: 0.2759\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8321 - accuracy: 0.2759\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8266 - accuracy: 0.2759\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8211 - accuracy: 0.2759\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8155 - accuracy: 0.2759\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8100 - accuracy: 0.2759\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8044 - accuracy: 0.2759\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7989 - accuracy: 0.2759\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7933 - accuracy: 0.3103\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7878 - accuracy: 0.3103\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7822 - accuracy: 0.3103\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7766 - accuracy: 0.3103\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7710 - accuracy: 0.3103\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7654 - accuracy: 0.3103\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7597 - accuracy: 0.3103\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7540 - accuracy: 0.3103\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7481 - accuracy: 0.3448\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7423 - accuracy: 0.3793\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7363 - accuracy: 0.4138\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7302 - accuracy: 0.4138\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7241 - accuracy: 0.4138\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7179 - accuracy: 0.4138\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7116 - accuracy: 0.4138\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7052 - accuracy: 0.4138\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6987 - accuracy: 0.4138\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6921 - accuracy: 0.4138\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6855 - accuracy: 0.4138\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6788 - accuracy: 0.4138\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6721 - accuracy: 0.4138\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6652 - accuracy: 0.4138\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6583 - accuracy: 0.4138\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6513 - accuracy: 0.4138\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6442 - accuracy: 0.4138\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6370 - accuracy: 0.4138\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6297 - accuracy: 0.4138\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6223 - accuracy: 0.4138\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6149 - accuracy: 0.4138\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6073 - accuracy: 0.4138\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5997 - accuracy: 0.4138\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5920 - accuracy: 0.4138\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5841 - accuracy: 0.4138\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5762 - accuracy: 0.4138\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5682 - accuracy: 0.4138\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5601 - accuracy: 0.4138\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5519 - accuracy: 0.4138\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5436 - accuracy: 0.4138\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5352 - accuracy: 0.4483\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5268 - accuracy: 0.4483\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5182 - accuracy: 0.4483\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5096 - accuracy: 0.4828\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5008 - accuracy: 0.4828\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4920 - accuracy: 0.4828\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4830 - accuracy: 0.5172\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4740 - accuracy: 0.5172\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4649 - accuracy: 0.5172\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4557 - accuracy: 0.5172\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4464 - accuracy: 0.5172\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4370 - accuracy: 0.5172\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4276 - accuracy: 0.5172\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4180 - accuracy: 0.5172\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4084 - accuracy: 0.5172\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3987 - accuracy: 0.5517\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3889 - accuracy: 0.5517\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3791 - accuracy: 0.5517\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3691 - accuracy: 0.5517\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3591 - accuracy: 0.5517\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3490 - accuracy: 0.5862\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3389 - accuracy: 0.6207\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3287 - accuracy: 0.6207\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3184 - accuracy: 0.6207\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3080 - accuracy: 0.6207\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2976 - accuracy: 0.6552\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2872 - accuracy: 0.6897\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2766 - accuracy: 0.6897\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2660 - accuracy: 0.6897\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2554 - accuracy: 0.7241\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2447 - accuracy: 0.7241\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2340 - accuracy: 0.7241\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2232 - accuracy: 0.7586\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2123 - accuracy: 0.7586\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2015 - accuracy: 0.7586\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1905 - accuracy: 0.7586\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1796 - accuracy: 0.7586\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1685 - accuracy: 0.7931\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1575 - accuracy: 0.7931\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1464 - accuracy: 0.7931\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1353 - accuracy: 0.7931\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1241 - accuracy: 0.7931\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1129 - accuracy: 0.7931\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1017 - accuracy: 0.7931\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0905 - accuracy: 0.8276\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0792 - accuracy: 0.8276\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0679 - accuracy: 0.8276\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0566 - accuracy: 0.8276\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0453 - accuracy: 0.8966\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0339 - accuracy: 0.8966\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0226 - accuracy: 0.8966\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0112 - accuracy: 0.8966\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9998 - accuracy: 0.8966\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9885 - accuracy: 0.8966\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9771 - accuracy: 0.8966\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9657 - accuracy: 0.8966\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9544 - accuracy: 0.8966\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9430 - accuracy: 0.8966\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9317 - accuracy: 0.8966\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9204 - accuracy: 0.8966\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9092 - accuracy: 0.8966\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8979 - accuracy: 0.8966\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8867 - accuracy: 0.8966\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8755 - accuracy: 0.8966\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8644 - accuracy: 0.8966\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8533 - accuracy: 0.8966\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8423 - accuracy: 0.8966\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8313 - accuracy: 0.8966\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8204 - accuracy: 0.8966\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8096 - accuracy: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "tBvCA_SSMeRL",
        "outputId": "28ad98a0-c277-4163-c8a6-315dc535f99c"
      },
      "source": [
        "# Model Accuracy\n",
        "plt.plot(train.history['accuracy'],label='training set accuracy')\n",
        "plt.plot(train.history['loss'],label='training set loss')\n",
        "plt.legend(['accuracy','loss'])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVf7H8fc3BQIk9N5BEOmgASmKIKKgInaxd3Qta9nmqr9VV3d13V27oqiAqCg2lHXXBkpRQOlNkBokgBICUhNIOb8/zgABEwiQmTvJfF7PMw/JnTsz39wM88k5595zzDmHiIjErrigCxARkWApCEREYpyCQEQkxikIRERinIJARCTGJQRdwOGqWbOma9q0adBliIiUKrNmzdronKtV2H2lLgiaNm3KzJkzgy5DRKRUMbPVRd2nriERkRinIBARiXEKAhGRGFfqxghEpGzLyckhPT2d7OzsoEsplZKSkmjYsCGJiYnFfoyCQESiSnp6OikpKTRt2hQzC7qcUsU5R2ZmJunp6TRr1qzYj1PXkIhElezsbGrUqKEQOAJmRo0aNQ67NaUgEJGooxA4ckdy7GKnayjjB1j4PlRtAtWa+ltKPYhTFopIbIudIPh5IUx6HCiw/kJ8Oaja2IfC3oAoEBRJVQIpVUQkkmInCNpdAMcNhC1rYHMa/LLa/7s5DTavhvSZkP3L/o9JqrovFKo397cax/h/k+uAmq8ichRyc3NJSAj+Yzj4CiIpoZz/IK9xTOH3Z/0SCogCIfHLavhpPiz5GPJz9+2bWDEUDs32hUT15lDzWIWESBlw7rnnsmbNGrKzs7njjjsYMmQIn376Kffeey95eXnUrFmTCRMmsH37dm6//XZmzpyJmfHAAw9wwQUXkJyczPbt2wF47733+Pjjjxk5ciTXXHMNSUlJzJkzh549ezJ48GDuuOMOsrOzqVChAiNGjKBVq1bk5eXxpz/9iU8//ZS4uDhuvPFG2rZtyzPPPMOHH34IwBdffMELL7zA2LFjj+pnja0gOJQKVf2tXsdf35eX61sTm1aGbqv8vxlLYelnkLe7wPNUg9ptoHZrqHXcvq8rVo/czyJSBjz0n0V8v25riT5nm/qVeWBg20PuN3z4cKpXr05WVhZdunRh0KBB3HjjjUyePJlmzZqxadMmAB5++GGqVKnCggULANi8efMhnzs9PZ2pU6cSHx/P1q1bmTJlCgkJCYwfP557772X999/n2HDhpGWlsbcuXNJSEhg06ZNVKtWjVtuuYWMjAxq1arFiBEjuO66647ugKAgKL74hNBf/82Avvvfl58HW9dC5grYuAw2fA8bFsP8d2HXln37Jdf1IdPgeKjf2d+Sa0f0xxCR4nnmmWf2/qW9Zs0ahg0bRq9evfaen1+9uv/Dbvz48bz99tt7H1etWrVDPvdFF11EfHw8AFu2bOHqq69m2bJlmBk5OTl7n/fmm2/e23W05/WuvPJK3njjDa699lqmTZvGqFGjjvpnVRCUhLh4P+hctTEc02ffdudg6zrIWOyD4edFsG4uLPucvYPWlRtC/U7Q6ERo0hPqdYD44l8RKFKWFecv93CYOHEi48ePZ9q0aVSsWJHevXvTqVMnlixZUuznKHga54Hn9VeqVGnv1//3f/9Hnz59GDt2LGlpafTu3fugz3vttdcycOBAkpKSuOiii0pkjEFBEE5mUKWBv7U4bd/2Xdv9uMO6ObB2Nqyd5ccgABIrQaMuPhSa9ICGXSChfDD1i8SoLVu2UK1aNSpWrMiSJUuYPn062dnZTJ48mVWrVu3tGqpevTr9+vXj+eef56mnngJ811C1atWoU6cOixcvplWrVowdO5aUlJQiX6tBgwYAjBw5cu/2fv368dJLL9GnT5+9XUPVq1enfv361K9fn0ceeYTx48eXyM+rk+iDUD7Zf8h3vxUufBXumAu/+wEuHAGdL4cdG+Grv8PIs+AfzWD0YJjxih/EFpGw69+/P7m5ubRu3Zp77rmHbt26UatWLYYNG8b5559Px44dueSSSwC4//772bx5M+3ataNjx4589dVXADz22GOcffbZ9OjRg3r16hX5Wn/84x/585//TOfOncnN3XdCyg033EDjxo3p0KEDHTt2ZPTo0Xvvu/zyy2nUqBGtW7cukZ/XnHOH3iuKpKamuphYmCZrM/w4HZZP8F1Jv4RCoOax0KIftBrgwyQuPtg6RUrY4sWLS+wDrqy67bbb6Ny5M9dff32h9xd2DM1slnMutbD91TUUrSpU8x/2rQb4sYbM5bDsC1j+Bcx4GaY/D5VqQ+uB0GaQ70qK169TpKw74YQTqFSpEv/+979L7Dn1yVEamEHNlv7W/RY/xrD8C1j0Icx7C2a+CpVqQbsLodNlfsBZRMqkWbNmlfhzKghKo/LJ0PY8f9u904fCwvd9IHw7FOq094HQ4WKoVDPoakUkymmwuLQrV9F3DV08yg84n/kvf/rpZ3+GJ1rDB0NgzQzfvSQiUgi1CMqSitWh643+tmExzBwBc0fD/DH+QrauQ3z3UWJS0JWKSBRRi6Csqt0aznwcfrcYzvo35O6Cj26Fp9rDlCcge8uhn0NEYoKCoKwrnwJdboBbpsNVH0HddjDhIXiyHXzxF9j2U9AVikSd5OTkoEuIKAVBrDCD5r3hyrEwZJK/0nnqs/BUB/j0z7B9Q9AVikhAFASxqH4nuGgE3D4L2l8E374ET3f0LYQdmUFXJxI1nHP84Q9/oF27drRv354xY8YAsH79enr16kWnTp1o164dU6ZMIS8vj2uuuWbvvk8++WTA1RefBotjWfXmcO7zcPLdMPEx+OYZmPEq9Ljd38pVOvRziITTJ/fATwtK9jnrtocBjxVr1w8++IC5c+cyb948Nm7cSJcuXejVqxejR4/mjDPO4L777iMvL4+dO3cyd+5c1q5dy8KFCwH45ZdfDvHs0UMtAvEL9Vzwsh9HOOZUmPgoPHM8zH7dT7EtEqO+/vprLr30UuLj46lTpw6nnHIKM2bMoEuXLowYMYIHH3yQBQsWkJKSQvPmzVm5ciW33347n376KZUrVw66/GJTi0D2qX0cXPI6/PgtfH4fjLsNvn0RTn/YB4RIpBXzL/dI69WrF5MnT+a///0v11xzDXfffTdXXXUV8+bN47PPPuPFF1/knXfeYfjw4UGXWixqEcivNT4Rrv8CLhoJu7bB6+fBGxfAz98HXZlIRJ188smMGTOGvLw8MjIymDx5Ml27dmX16tXUqVOHG2+8kRtuuIHZs2ezceNG8vPzueCCC3jkkUeYPXt20OUXm1oEUjgzP4VFqzPhu2Ew+Z/wYk844Vrocx9UqhF0hSJhd9555zFt2jQ6duyImfH4449Tt25dXnvtNf75z3+SmJhIcnIyo0aNYu3atVx77bXk5+cD8OijjwZcffFpGmopnp2b/NjBjFehXDL0/hN0uRESygVdmZQxmob66B3uNNRh6xoys0Zm9pWZfW9mi8zsjkL2MTN7xsyWm9l8Mzs+XPXIUapYHc78J/xmKjRMhc/uhRe6wQ+faB4jkVIunGMEucDvnHNtgG7ArWbW5oB9BgAtQ7chwNAw1iMlofZxcMX7cNm7YHHw1mB4/Vy/HrOIlEphCwLn3Hrn3OzQ19uAxUCDA3YbBIxy3nSgqpkVvaabRAczOPZ0uGUa9P8HrJsLL54EH9/tl9kUOUqlrcs6mhzJsYvIWUNm1hToDHx7wF0NgDUFvk/n12GBmQ0xs5lmNjMjIyNcZcrhik+EbjfDb+f4+YxmjfTXH0x9DnJ3B12dlFJJSUlkZmYqDI6Ac47MzEySkg5vhuGwnzVkZsnA+8CdzrmtR/IczrlhwDDwg8UlWJ6UhD3jB6nX++sPPr/PL5Jz+t/8UptmQVcopUjDhg1JT09Hf/QdmaSkJBo2bHhYjwlrEJhZIj4E3nTOfVDILmuBRgW+bxjaJqXRnvGDZV/4weS3L/UT3Z3xd6jTNujqpJRITEykWbNmQZcRU8J51pABrwKLnXNPFLHbOOCq0NlD3YAtzrn14apJIqRlP3920YDH940f/OcO2Lw66MpEpBBhu47AzE4CpgALgPzQ5nuBxgDOuRdDYfEc0B/YCVzrnDvoRQK6jqCU2bnJT2g3czjgoP3FcNJdUOvYoCsTiSkHu45AF5RJZGxJ94PIs0ZCbja0OQd6/BYanKAxBJEIUBBI9NixEaa/AN+9DLu2Qt0O0OV6aHeBX01NRMJCQSDRZ9c2mP+O7zL6eSEkVIBW/aHdhX6MIaF80BWKlCkHCwJNOifBKJ/iWwKp10H6DJg/BhaN9bfEStD8FB8ILfpB1UaHfj4ROWIKAgmWGTTq6m/9H4OVk2DpJ7Dsc/jhf36fWsdB8z7QrBc06QEVqgZbs0gZo64hiU7OwcZlPhCWj4cfp0Nulp/fqF4n32Jo1gsadYNyFYOuViTqaYxASr/cXZA+E1ZNglWTfXdSfi7EJfrWRLNe0OwUfxaSpsYW+RUFgZQ9u7bDmuk+FFZOgvXzAAeJFaFx91Aw9IJ6HSEuPuhqRQKnwWIpe8onQ4vT/A0gazOkfeODYdVkGP+A355UBZqe7FsLrQZo4FmkEGoRSNm07WdIm7KvK2lzmt9eryMcNxBan+0HoXUxm8QIdQ2JZK6Axf+BJf+F9O/8turN4bizofVAaJAKcRGZlV0kEAoCkYK2/eQDYcnHvrWQnwvJdaDVmX7qi6Yn+7UWRMoQBYFIUbJ+8dNmL/kPLBsPOTugQjVodRa0GeRPU9VVzlIGaLBYpCgVqkKHi/wtJwuWT4DF4/xt7htQvjIc29+HQou+kFgh6IpFSpyCQGSPxAp+ELn12f66hZWTYPFHvhtpwTt+6ouW/XwotDzdn7kkUgaoa0jkUPJyIO1r+P4jP66wIwMSkvypq63P8ZPlJVUJukqRg9IYgUhJyc/z0118/5E/C2nbOn918zF9fCgcd5Zfw1kkyigIRMIhPx/WzoLvP/RjCr/8CBYPzU6Gtuf7LiRNkCdRQkEgEm7Owfq58P0431rYtALiy/mxhA4XQ8szIDEp6ColhikIRCLJOVg3Bxa8Cwvegx0boHwVf41Ch0ugSU9dvCYRpyAQCUperp/mYsG7fkxh93ao3MAvzdlxMNRpG3SFEiMUBCLRYPdOv9jOgnf9Ggv5uVC/M3S+0geDxhMkjBQEItFmx0YfCLNfhw2L/OmobQZB5yugyUnqOpISpyAQiVZ7xhPmvOHHE3ZtgWpNodMV0OkyqNIg6AqljFAQiJQGOVl+HGHO634yPIuDY/pCl+v92UdaYEeOguYaEikNEiv4U007XOzXT5jzpg+FtwZDlUZwwtVw/NWQXDvoSqWMUYtAJJrl5cLST2DGK7Byor+KufVA6HIDNOmhhXWk2NQiECmt4hP8B3/rgbBxOcwc7mdFXfQB1Grtu406XAJJlYOuVEoxtQhESpvdO30QzHjFDzQnVoLOl8OJN0ONY4KuTqKUBotFyqq1s+C7l/0ZR/m50GoAdLsFmp6kbiPZj4JApKzb9pNvIcx4FbI2Qd320O1WaHe+VlgT4OBBoKtWRMqClLpw6v1w9/cw8Gm/hsKHN8NT7WHyPyFrc9AVShRTEIiUJYkV4IRr4JbpcMX7UKcdfPkIPNkOPr8ftq4PukKJQgoCkbLIzK+gduUHcPPXft3lac/D0x1g3G8hc0XQFUoUURCIlHV128OFr8Lts/xcRvPehudS4d1rYP28oKuTKKAgEIkV1ZvD2U/CnfOhx29h2Xh4qRe8fr5fk1liVtiCwMyGm9kGM1tYxP29zWyLmc0N3f4SrlpEpICUutDvIbhrIfT9C/w0H0aeBSPOUiDEqHC2CEYC/Q+xzxTnXKfQ7a9hrEVEDlShKpz8O7hzAfT/B2Qu84Ew8mxI+ybo6iSCwhYEzrnJwKZwPb+IlJDECtDtZrhjHpzxKGT8ACPPhNcGwuppQVcnERD0GEF3M5tnZp+YmdbsEwlSYgXofksoEP4OG5bAiP4wahD8OD3o6iSMggyC2UAT51xH4Fngw6J2NLMhZjbTzGZmZGRErECRmFSuInS/1QfC6X+DnxfB8DNg1Ll+SgspcwILAufcVufc9tDX/wMSzaxmEfsOc86lOudSa9WqFdE6RWJWuYrQ47ZQIDziB5VfPhXeuQo2Lgu6OilBgQWBmdU187NimVnXUC2ZQdUjIkUoVwl63O4D4ZR7YPkEeP5Ef2Ha1nVBVyclIGzrEZjZW0BvoKaZpQMPAIkAzrkXgQuB35hZLpAFDHalbQY8kVhSPgX6/NkvijPlX36Cu/lj4MSboOedULF60BXKEdLsoyJyZDavhq/+7sMgqbIPgxNv9l1KEnU0+6iIlLxqTeD8l+A330Dj7jDhIXimM8weBfl5QVcnh0FBICJHp05buGwMXPspVG0M4273U1esnBh0ZVJMCgIRKRlNusP1n8OFI2DXVn/9wehLIGNp0JXJISgIRKTkmPlV0W6dAac9BKunwgvd4H9/gB06KTBaKQhEpOQlJsFJd8Lts/1COTNe8eMHU5+F3F1BVycHUBCISPgk14Kzn4DfTIVGXf0qac93hcX/gVJ2xmJZpiAQkfCr3RqueA+u+AASK8KYK+D18zR+ECUUBCISOS36wk1TYMDjsG42DO0On90H2VuDriymHVYQmFmcmVUOVzEiEgPiE/zVyLfPhk6X+bWUn0uFuW9Bfn7Q1cWkQwaBmY02s8pmVglYCHxvZn8If2kiUqZVqgnnPAs3ToAqjeDDm/0sp+vmBF1ZzClOi6CNc24rcC7wCdAMuDKsVYlI7GhwAlz/BQx6ATavgmF9/IR2Ot00YooTBIlmlogPgnHOuRxAw/0iUnLi4qDz5XD7LOh2C8x5A57tDN8Og7zcoKsr84oTBC8BaUAlYLKZNQE0siMiJS+pCvT/uz/dtF4n+OQP8HIfSNeCOOF0yCBwzj3jnGvgnDvTeauBPhGoTURiVe3j4KqP4KKRsCMDXukLH98FWZuDrqxMKs5gcR0ze9XMPgl93wa4OuyViUhsM4O258Gt3/nprWeNhOe6wLwxuhithBWna2gk8BlQP/T9UuDOcBUkIrKfpMow4DEYMhGqNoGxQ+C1gboYrQQVJwhqOufeAfIBnHO5gCYbF5HIqtfRn1109pN+/eShPWDCX2H3zqArK/WKEwQ7zKwGoTOFzKwbsCWsVYmIFCYuDlKvg9tmQfsLYcq/4YUTYelnQVdWqhUnCO4GxgHHmNk3wCjg9rBWJSJyMMm14LwX4eqPISEJRl/s5y/aui7oykqlYq1ZbGYJQCvAgB9C1xIEQmsWi8h+cnfDtGdh0uMQXw5OewBOuM63HmSvg61ZfMggMLOrCtvunBtVArUdNgWBiBQqc4U/xXTVJGh0Igx82s96KsDRL17fpcDtZOBB4JwSq05EpCTUOMZfe3Dui7BxKbx4Mnz5N8jJDrqyqJdwqB2cc/uNB5hZVeDtsFUkInKkzKDTpdCyH3x2L0x+HBaN9a2Dpj2Dri5qHUkn2g78xHMiItGpUk04f5hfCCdvN4w8E8bdriuTi3DIFoGZ/Yd9k8zFAW2Ad8JZlIhIiWjRF26ZBhMf8+se/PApDPiHv2LZLOjqokZxBotPKfBtLrDaOZce1qoOQoPFInJE1s/z01uvnwstz4Cz/g1VGwVdVcQc1VlD0UZBICJHLC8XvnsJvnwEMDjtQehyQ0ycanpEZw2Z2TYz21rIbZuZaRpqESl94hOg+61wy3Ro3M1Pcz1iAGxcFnRlgSoyCJxzKc65yoXcUpxzWrdYREqvak3givf9qaYZS2BoT5jyRMwuglPs9pCZ1Tazxntu4SxKRCTs9pxqeut3cOwZMOEheOVUWD8/6MoirjjrEZxjZsuAVcAk/Gpln4S5LhGRyEipA5e8DhePgq3r/YpoEx6OqQvRitMieBjoBix1zjUD+gLTw1qViEiktRkEt34L7S+GKf+Cl06GNd8FXVVEFCcIcpxzmUCcmcU5574CCh15FhEp1SpWh/OG+vGDnCx49XT45B7YvSPoysKqOEHwi5klA1OAN83safzVxSIiZVOL0/yFaF1ugG+HwgvdYMVXQVcVNsUJgq+AKsAdwKfACmBgOIsSEQlc+RQ4619w7ScQlwivnwsf3QZZvwRdWYkrThAkAJ8DE4EUYEyoq0hEpOxr0gN+8w30vBPmjvatgyX/C7qqEnXIIHDOPeScawvcCtQDJpnZ+EM9zsyGm9kGM1tYxP1mZs+Y2XIzm29mxx929SIikZBYAfo9BDdOgIo14O1L4d1rYXtG0JWViMO5rnoD8BOQCdQuxv4jgf4HuX8A0DJ0GwIMPYxaREQir35nuPEr6HM/LPkYnu8K89+BUjZVz4GKcx3BLWY2EZgA1ABudM51ONTjnHOTgU0H2WUQMMp504GqZlaveGWLiAQkoRyc8ge4aQpUbw4f3AijL4Eta4Ou7IgVp0XQCLjTOdfWOfegc+77EnrtBsCaAt+nh7b9ipkNMbOZZjYzI6NsNMVEpJSrfRxc/zmc8SikTYHnT4SZwyE/P+jKDltxxgj+7JybG4liDlLDMOdcqnMutVatWkGWIiKyT1w8dL8FfjMVGnT2ayaPOsevn1yKBDn36lp8a2OPhqFtIiKlS/VmcNU4GPiMX/dgaE+Y+izk5wVdWbEEGQTjgKtCZw91A7Y459YHWI+IyJEzgxOu9tNUNO8Nn98Pr/aDn0uqNz18whYEZvYWMA1oZWbpZna9md1sZjeHdvkfsBJYDrwM3BKuWkREIqZyfbj0LbjgVdicBi/18ktl5u4OurIiaYUyEZFw2bERPr0HFrwLtdvAoOegwQmBlHJEK5SJiMhRqlQTLngFLn3bT03xymm+y2j3zqAr24+CQEQk3FoNgFunQ+cr/SDyiz0h7eugq9orIegCRESiXdbuPC56aSobtu46ymc6h9T4Zty7aSgNR57F+3Gn81zcleywisV69FXdm3DbqS2PsoZfUxCIiBzCjLRNLFy7lTPa1qF6pXJH+Wx9GZbfg34/vcp5G9+lb/xcPmzwe36o3P2Qj2xRO/koX7twCgIRkUOYtjKThDjjyUs6UbFcSX1sngjpQ6j60a1ck/ZHvzJa/8egUo0Sev7i0xiBiMghTF+ZScdGVUswBEIapsJNk6HXH2HRB34Su4UfRHwSOwWBiMhBbN+Vy/z0LXRvHqa/1BPKw6n3wZBJUKUhvHctvHUpbEkPz+sVQkEgInIQM9M2kZfv6BauINijbju4YQL0exhWTvST2E0fGpFpKjRGICISsmFrNreNnsP2Xbl7t2Xu2EVivHF8k6rhLyA+AXr+FtqcA//9nb8Ybf47MPBpqHfI2f+PmFoEIiIhz321nNk/bqZ+1STqV61A/aoVaN+gKnf3a1Xy4wMHU60pXP6en6bilx9hWG/44i9huxBNLQIREWD9lize/m4NF6U25NHzw/fXd7GZQfsL4ZhTfQh88zTs2gZnP1niL6UgEJEyzTnHg+MWsWjd1oPul7F9F/nOcUvvFhGqrJgqVvdzFHUc7FsKYaAgEJEybeqKTF6btpr2DapQuULRH3kNq1Xgqu5NaVS9eFf5RlzTk8L21AoCESmznHM8NX4pdSsn8d5vulM+IT7okqKSgkBESr2JP2xgxDdpHHgZVk5uPjPSNvPwoLYKgYNQEIhIqZaTl8/9Hy4ka3deod06Z7Stw8VdGhXySNlDQSAipdr7s9JJ35zFiGu60Oe42kGXUyopCESkVMnanceD4xaxJSsHgJmrN9GxUVV6t6oVcGWll4JAREqV16enMWbmGlrWTibOjNopSdx3ZmvMLOjSSi0FgYiUGjt35/LSpJWc3LImr19/YtDllBkKAhGJah/PX8eXizcAsG5LFpk7dnPnaccGXFXZoiAQkai1ecdu/vTefBLi4/ZeDDa4SyNOaFIt4MrKFgWBiEStl6esZGdOHp/d2pNj66QEXU6ZpdlHRSQqbdqxm9empnFW+3oKgTBTEIhIVNrTGrijb8ugSynzFAQiEnUyt+/italpnN2hPi3VGgg7jRGISKA2bMtmxDdp5OXvmylo8fqtZOXkcUffKJsSuoxSEIhIoB7/9Afen51O0gGTwl3ZrQktaqs1EAkKAhEJTNrGHYyds5brejbj/85uE3Q5MUtjBCISmGe/XE5ivHHTKc2DLiWmKQhEJBCrNu5g7Jx0rjixCbVTkoIuJ6YpCEQkEM9+uYxyCXHcdMoxQZcS8zRGICJh82PmTj5b9BPugLXDcvIcH85Zy/UnNaNWSvmAqpM9FAQiEhbOOX7/3jy+W7Wp0PurVkxkSC+1BqKBgkBEwmLaiky+W7WJ+89qzaVdG//q/nIJcSTGq3c6GoQ1CMysP/A0EA+84px77ID7rwH+CawNbXrOOfdKOGsSkcOXnZPHR3PXsjvvwOXhi/bOjDXUrZzEFd2akJSoheOjWdiCwMzigeeBfkA6MMPMxjnnvj9g1zHOudvCVYeIHL2hE1fw9IRlh/24v5/XXiFQCoSzRdAVWO6cWwlgZm8Dg4ADg0BEotiWrByGf7OK01rX4dHz2xf7cQlxRrVK5cJYmZSUcAZBA2BNge/TgcLWlrvAzHoBS4G7nHNrDtzBzIYAQwAaN/51X6OIlKw5P25mZcYOAL5ZsZFt2bnc3e9YneFTRgU9WPwf4C3n3C4zuwl4DTj1wJ2cc8OAYQCpqanF76QUkcO2YWs2g4dNZ1du/t5tZ7WvR5v6lQOsSsIpnEGwFmhU4PuG7BsUBsA5l1ng21eAx8NYj4gUwwsTV5Cb73j/Nz2olexbAPWq6srfsiycQTADaGlmzfABMBi4rOAOZlbPObc+9O05wOIw1iMihdiWncPUFZk459iVm8/o737kguMbaF3gGBK2IHDO5ZrZbcBn+NNHhzvnFpnZX4GZzrlxwG/N7BwgF9gEXBOuekSkcA+MW8QHs/c11svFx3FbH60KFkvMudLV5Z6amupmzpwZdBkiZcLKjO2c9sQkBndtzJXdmgD+it96VSoEXJmUNDOb5ZxLLey+oAeLRcqkvHzHt6syyTmMC7CC8Mb01ZRLiOOu03RGUCxTEIiEwahpaTz0n9JxycFClq4AAAxjSURBVMxNvZorBGKcgkCkhGXn5PHCxBV0aVqNewa0Drqcg4ozaFu/StBlSMAUBCHbsnNY8tM2EuPj6NCgCnFx9qt9snPyWLRuC/lH2dpvUqOiFuIow9789kcytu3i2Us768wbKRUUBCH3f7iQj+auA+Chc9pydY+mv9rnkf9+zxvTfzzq12pYrQJf/q435RI082JZk7U7j6ETV9C9eQ26Na8RdDkixaIgCPlpSzbH1U2hUvkEnv9qOZd0abTfZFnpm3cyZsYazulYn4tTGx3kmQ5uRcZ2Hhi3iPdmpXPZiZouo6x589vVbNy+ixcuPz7oUkSKTUEQsjU7l4bVKnL9Sc249OXpDJ24gtPb1tl7/6tTVmEY9ww4jvpVj/zUup4tavDh3LU8/9VyOjSsgv26BwqAWsnlqV1Z3UelSdbuPF6ctJKeLWrQtVn1oMsRKTYFQcjWrBxa10uh+zE16Na8Ok9PWParaXev7NbkqEIAwMy467RjuWr4d5z97NdF7pdSPoEZ95+mKXxLkTem+9bA0NPUGpDSRUEQsjU7h8pJiQA8d9nxzFq9eb/7483o0aJk+nx7HVuLt4d0Y0tWTqH3//DTNp74YilzfvyF7seon7k02Lk7l5cmr+CkFjXp0lStASldFARAfr5j+65cKlfwQVAzuTxntK0b1tc82EBi92Nq8NT4pUxfmakgCFBOXj7pm7OKte+Hc9aycftu7jxNUzNI6aMgALbtysU5qBIKgqBVTkqkXYMqTFuZyV1BFxPDfv/uvL1nkhXHyS1rkqrWgJRCCgL8+ABA5aToORzdmtdg5DdpZOfkaZwgAD/8tI1x89ZxfucG9Dq2VrEeU1JdhyKRFj2ffAHa01dfOUpaBADdm9dg2OSVTPxhA8c3Lv0XJSUnJVCx3JG93bZk5bArJ6+EKzq4J79YSqVyCfxlYBuqVtRyi1K2KQjwA8XA3sHiaJDatBoJccbNb8wOupQSUa1iIl/9vvdhf6jO/nEzFw6detRXcx+J2/q0UAhITFAQAFuzcgGoXCF6DkdKUiKvXdeVtMwdQZdy1HbsyuXv/1vCq1+v4nentzqsxz7x+VKqVSzHXf2OLfKai3BIjItjYMf6kXtBkQBFzydfgKKxRQDQs0VNeraoGXQZJWLuml8Y8U0al3ZtTEoxx2Lmp2/h6+Ubue/M1lwRmitfREqegoACg8VRNEZQ1tzR91j+t+Anejz25WE9rmZyOYWASJgpCPDTS5j5q3klPFrVTeHlq1JZfZhdXalNq1OhnM6aEgknffLhWwTJ5RMKnXpaSk6/NnUOvZOIRJzmQWb/6SVERGKNggB/1pDGB0QkVikI2NMiUC+ZiMQmBQF+jEAtAhGJVQoCYFt2rsYIRCRmKQjY0yJQ15CIxKaYD4K8fMe2XblRMwW1iEikxXwQbIvS6SVERCIl5oNg34RzCgIRiU0xHwQbd+wCKPZEaCIiZU3MB8Hob3+kfEIcnRtXDboUEZFAxHQQpG3cwdg5a7miWxNqpyQFXY6ISCBipj9k0tIMHvn4+/22/ZKVQ2K8cdMpzQOqSkQkeDETBMnlE2hZJ/lX2/u0qq3WgIjEtJgJghOaVOOEJicEXYaISNSJ6TECEREJcxCYWX8z+8HMlpvZPYXcX97MxoTu/9bMmoazHhER+bWwBYGZxQPPAwOANsClZtbmgN2uBzY751oATwL/CFc9IiJSuHC2CLoCy51zK51zu4G3gUEH7DMIeC309XtAXzPTepEiIhEUziBoAKwp8H16aFuh+zjncoEtQI0Dn8jMhpjZTDObmZGREaZyRURiU6kYLHbODXPOpTrnUmvVqhV0OSIiZUo4g2At0KjA9w1D2wrdx8wSgCpAZhhrEhGRA4QzCGYALc2smZmVAwYD4w7YZxxwdejrC4EvnXMujDWJiMgBLJyfu2Z2JvAUEA8Md879zcz+Csx0zo0zsyTgdaAzsAkY7JxbeYjnzABWH2FJNYGNR/jYcIvW2lTX4YnWuiB6a1Ndh+dI62rinCu0bz2sQRBtzGymcy416DoKE621qa7DE611QfTWproOTzjqKhWDxSIiEj4KAhGRGBdrQTAs6AIOIlprU12HJ1rrguitTXUdnhKvK6bGCERE5NdirUUgIiIHUBCIiMS4mAmCQ02JHcE6GpnZV2b2vZktMrM7QtsfNLO1ZjY3dDszgNrSzGxB6PVnhrZVN7MvzGxZ6N9qAdTVqsBxmWtmW83sziCOmZkNN7MNZrawwLZCj5F5z4Tec/PN7PgI1/VPM1sSeu2xZlY1tL2pmWUVOG4vRriuIn9vZvbn0PH6wczOCFddB6ltTIG60sxsbmh7JI9ZUZ8R4XufOefK/A1/QdsKoDlQDpgHtAmolnrA8aGvU4Cl+Gm6HwR+H/BxSgNqHrDtceCe0Nf3AP+Igt/lT0CTII4Z0As4Hlh4qGMEnAl8AhjQDfg2wnWdDiSEvv5HgbqaFtwvgONV6O8t9P9gHlAeaBb6PxsfydoOuP/fwF8COGZFfUaE7X0WKy2C4kyJHRHOufXOudmhr7cBi/n1rKzRpOBU4a8B5wZYC0BfYIVz7kivLj8qzrnJ+KvgCyrqGA0CRjlvOlDVzOpFqi7n3OfOz+oLMB0/31dEFXG8ijIIeNs5t8s5twpYjv+/G/HazMyAi4G3wvX6RTnIZ0TY3mexEgTFmRI74syvyNYZ+Da06bZQ0254EF0wgAM+N7NZZjYktK2Oc2596OufgDoB1FXQYPb/zxn0MYOij1E0ve+uw//VuEczM5tjZpPM7OQA6ins9xZNx+tk4Gfn3LIC2yJ+zA74jAjb+yxWgiDqmFky8D5wp3NuKzAUOAboBKzHN0sj7STn3PH4VeVuNbNeBe90vh0a2PnG5icvPAd4N7QpGo7ZfoI+RoUxs/uAXODN0Kb1QGPnXGfgbmC0mVWOYElR93srxKXs/wdHxI9ZIZ8Re5X0+yxWgqA4U2JHjJkl4n/BbzrnPgBwzv3snMtzzuUDLxPGJnFRnHNrQ/9uAMaGavh5TzMz9O+GSNdVwABgtnPuZ4iOYxZS1DEK/H1nZtcAZwOXhz48CHW9ZIa+noXviz82UjUd5PcW+PGCvVPinw+M2bMt0sessM8Iwvg+i5UgKM6U2BER6nt8FVjsnHuiwPaCfXrnAQsPfGyY66pkZil7vsYPNC5k/6nCrwY+imRdB9jvr7Sgj1kBRR2jccBVobM6ugFbCjTtw87M+gN/BM5xzu0ssL2W+TXFMbPmQEvgoLP+lnBdRf3exgGDzay8mTUL1fVdpOoq4DRgiXMufc+GSB6zoj4jCOf7LBKj4NFww4+sL8Un+X0B1nESvkk3H5gbup2Jn457QWj7OKBehOtqjj9jYx6waM8xwi8dOgFYBowHqgd03CrhFy2qUmBbxI8ZPojWAzn4vtjrizpG+LM4ng+95xYAqRGuazm+73jP++zF0L4XhH7Hc4HZwMAI11Xk7w24L3S8fgAGRPp3Gdo+Erj5gH0jecyK+owI2/tMU0yIiMS4WOkaEhGRIigIRERinIJARCTGKQhERGKcgkBEJMYpCETCzMx6m9nHQdchUhQFgYhIjFMQiISY2RVm9l1ovvmXzCzezLab2ZOheeEnmFmt0L6dzGy67Zvrf8/c8C3MbLyZzTOz2WZ2TOjpk83sPfPrA7wZunoUM3ssNO/8fDP7V0A/usQ4BYEIYGatgUuAns65TkAecDn+iuaZzrm2wCTggdBDRgF/cs51wF/NuWf7m8DzzrmOQA/8lavgZ5C8Ez+vfHOgp5nVwE+x0Db0PI+E96cUKZyCQMTrC5wAzDC/KlVf/Ad2PvsmH3sDOMnMqgBVnXOTQttfA3qF5mpq4JwbC+Ccy3b75vj5zjmX7vxEa3PxC51sAbKBV83sfGDvfEAikaQgEPEMeM051yl0a+Wce7CQ/Y50TpZdBb7Ow68cloufefM9/Ayhnx7hc4scFQWBiDcBuNDMasPe9WGb4P+PXBja5zLga+fcFmBzgcVJrgQmOb+aVLqZnRt6jvJmVrGoFwzNN1/FOfc/4C6gYzh+MJFDSQi6AJFo4Jz73szux6/QFoefkfJWYAfQNXTfBvw4AvhpgF8MfdCvBK4Nbb8SeMnM/hp6josO8rIpwEdmloRvkdxdwj+WSLFo9lGRgzCz7c655KDrEAkndQ2JiMQ4tQhERGKcWgQiIjFOQSAiEuMUBCIiMU5BICIS4xQEIiIx7v8BGVFVIzL73uAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqfJEGsC8qTm"
      },
      "source": [
        "Above plot shows that the model achieved 89% accuracy after 180 iterations and is training slowly after every iteration. Also, the model loss is reduced after every epoch with 0.8 at 200th  epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7nPfjkdMeRN"
      },
      "source": [
        "model.save('model.h5', train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmFDFL6HMeRU"
      },
      "source": [
        "#### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSkREajGMeRX",
        "outputId": "4a2aba2c-c048-4405-c0c1-15e9876cedc3"
      },
      "source": [
        "import random \n",
        "\n",
        "while True:\n",
        "  texts_p=[]\n",
        "  prediction_input=input('User:')\n",
        "\n",
        "\n",
        "  # Removing Punctuation and converting to lowercase\n",
        "  prediction_input=[letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input=''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "# Tokenizing and Padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "  \n",
        "\n",
        "# Getting output from model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "# Find the right tag and prediction\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  print(\"Bot:\", random.choice(responses[response_tag]))\n",
        "  if response_tag==\"goodbye\":\n",
        "    break\n",
        "    \n",
        "   \n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User:Hi there\n",
            "Bot: Hello, thanks for asking\n",
            "User:I am sad\n",
            "Bot: I’m sorry to hear you’re not doing well today\n",
            "User:Thanks for the help\n",
            "Bot: Any time!\n",
            "User:goodbye\n",
            "Bot: See you!\n"
          ]
        }
      ]
    }
  ]
}